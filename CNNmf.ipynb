{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa.display, os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa.display, os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import librosa\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "mel_train = []\n",
    "cqt_train = []\n",
    "mel_test = []\n",
    "cqt_test = []\n",
    "label_train = []\n",
    "label_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(audio_folder):\n",
    "    audio_files = []\n",
    "    labels = []\n",
    "\n",
    "    for root, dirs, files in os.walk(audio_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                audio_files.append(os.path.join(root, file))\n",
    "                labels.append(os.path.basename(root))\n",
    "\n",
    "    return audio_files, labels\n",
    "def process_audio(file_path):\n",
    "    sample_rate = 32000\n",
    "    n_mfcc = 13\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "\n",
    "    # Load audio file\n",
    "    audio, sample_rate = librosa.load(file_path, sr=sample_rate)\n",
    "\n",
    "    # Compute Mel spectrogram\n",
    "    mel = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mels=128)\n",
    "    # Compute MFCC from the Mel spectrogram\n",
    "    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=n_mfcc)\n",
    "\n",
    "    # Resize spectrograms\n",
    "    mfcc_resized = resize(mfcc, (224, 224, 3), mode='reflect', anti_aliasing=True)\n",
    "    mel_resized = resize(mel, (224, 224, 3), mode='reflect', anti_aliasing=True)\n",
    "\n",
    "    # Clear memory\n",
    "    del audio\n",
    "\n",
    "    return mfcc_resized, mel_resized\n",
    "def process_audio_files(audio_files, audio_folder):\n",
    "    mfcc_train = []\n",
    "    mel_train = []\n",
    "    y_train = []\n",
    "\n",
    "    total_files = len(audio_files)\n",
    "\n",
    "    with tqdm(total=total_files, ncols=80) as pbar:\n",
    "        for file_path in audio_files:\n",
    "            if file_path.endswith(\".wav\"):\n",
    "                # Process audio and extract spectrograms\n",
    "                mfcc, mel = process_audio(file_path)\n",
    "                # Append spectrograms and label to the train arrays\n",
    "                mfcc_train.append(mfcc)\n",
    "                mel_train.append(mel)\n",
    "                # Extract label from subfolder name\n",
    "                label = os.path.basename(os.path.dirname(file_path))\n",
    "                y_train.append(label)\n",
    "                pbar.set_postfix({'file': file_path})\n",
    "                pbar.update()\n",
    "\n",
    "    # Convert train arrays to NumPy arrays\n",
    "    mfcc_train = np.array(mfcc_train)\n",
    "    mel_train = np.array(mel_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    return mfcc_train, mel_train, y_train\n",
    "def main(audio_folder):\n",
    "    audio_files, labels = load_audio_files(audio_folder)\n",
    "    X_mfcc, X_mel, y = process_audio_files(audio_files, audio_folder)\n",
    "    return X_mfcc, X_mel, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "audio_folder = ''                        \n",
    "mfcc_test, mel_test, label_test = main(audio_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "audio_folder = ''                        \n",
    "mfcc_train, mel_train, label_train = main(audio_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on your label data\n",
    "label_encoder.fit(label_train)\n",
    "\n",
    "# Transform the labels to numerical values\n",
    "y_train_encoded = label_encoder.transform(label_train)\n",
    "y_test_encoded = label_encoder.transform(label_test)\n",
    "\n",
    "# Get the unique class names\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Create a dictionary to map numerical labels to class names\n",
    "label_to_class = {i: class_name for i, class_name in enumerate(class_names)}\n",
    "\n",
    "# Convert the encoded labels to one-hot encoded vectors\n",
    "label_train_encoded = to_categorical(y_train_encoded)\n",
    "label_test_encoded = to_categorical(y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "mel_train_norm = np.array(mel_train) / 255  \n",
    "mel_test_norm = np.array(mel_test) / 255      \n",
    "mfcc_train_norm = np.array(mfcc_train) / 255    \n",
    "mfcc_test_norm = np.array(mfcc_test) / 255    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input layers\n",
    "mel_input = Input(shape=(224, 224, 3))  # Modify the shape according to your mel spectrogram dimensions\n",
    "cqt_input = Input(shape=(224, 224, 3))\n",
    "\n",
    "# Convolutional layers for Mel spectrograms\n",
    "mel_conv = Conv2D(32, kernel_size=(3, 3), activation='relu')(mel_input)\n",
    "mel_conv = MaxPooling2D(pool_size=(2, 2))(mel_conv)\n",
    "mel_conv = Conv2D(64, kernel_size=(3, 3), activation='relu')(mel_conv)\n",
    "mel_conv = MaxPooling2D(pool_size=(2, 2))(mel_conv)\n",
    "mel_conv = Conv2D(128, kernel_size=(3, 3), activation='relu')(mel_conv)\n",
    "mel_conv = MaxPooling2D(pool_size=(2, 2))(mel_conv)\n",
    "mel_conv = Flatten()(mel_conv)\n",
    "\n",
    "# Convolutional layers for CQT spectrograms\n",
    "cqt_conv = Conv2D(32, kernel_size=(3, 3), activation='relu')(cqt_input)\n",
    "cqt_conv = MaxPooling2D(pool_size=(2, 2))(cqt_conv)\n",
    "cqt_conv = Conv2D(64, kernel_size=(3, 3), activation='relu')(cqt_conv)\n",
    "cqt_conv = MaxPooling2D(pool_size=(2, 2))(cqt_conv)\n",
    "cqt_conv = Conv2D(128, kernel_size=(3, 3), activation='relu')(cqt_conv)\n",
    "cqt_conv = MaxPooling2D(pool_size=(2, 2))(cqt_conv)\n",
    "cqt_conv = Flatten()(cqt_conv)\n",
    "\n",
    "# Merge the branches\n",
    "merged = concatenate([mel_conv, cqt_conv])\n",
    "\n",
    "# Dense layers for classification\n",
    "dense = Dense(256, activation='relu')(merged)\n",
    "dense = Dropout(0.5)(dense)  # Add dropout with a rate of 0.5\n",
    "dense = Dense(128, activation='relu')(dense)\n",
    "dense = Dropout(0.5)(dense)  # Add dropout with a rate of 0.5\n",
    "output = Dense(5, activation='softmax')(dense)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[mel_input, cqt_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping callback\n",
    "earlystop_callback = EarlyStopping(\n",
    "    monitor='val_accuracy', patience=5, mode='max', verbose=1, restore_best_weights=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit([mel_train_norm, mfcc_train_norm], label_train_encoded,\n",
    "           batch_size=32, epochs=100, \n",
    "          validation_data=([mel_test_norm, mfcc_test_norm], label_test_encoded),\n",
    "          callbacks=[earlystop_callback]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict([mel_test_norm, mfcc_test_norm])\n",
    "\n",
    "# Convert the predictions from one-hot encoded format to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(label_test_encoded, axis=1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "recall = recall_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
