{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 10:49:56.304697: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so, 0x0006): symbol not found in flat namespace (__ZN3tsl6Status22MaybeAddSourceLocationENS_14SourceLocationE)']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so, 0x0006): symbol not found in flat namespace (__ZN10tensorflow11TensorProtoC1Ev)']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa.display, os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa.display, os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, concatenate, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import librosa\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "mel_train = []\n",
    "cqt_train = []\n",
    "mel_test = []\n",
    "cqt_test = []\n",
    "label_train = []\n",
    "label_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(audio_folder):\n",
    "    audio_files = []\n",
    "    labels = []\n",
    "\n",
    "    for root, dirs, files in os.walk(audio_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                audio_files.append(os.path.join(root, file))\n",
    "                labels.append(os.path.basename(root))\n",
    "\n",
    "    return audio_files, labels\n",
    "def process_audio(file_path):\n",
    "    sample_rate = 32000\n",
    "    n_mfcc = 13\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "\n",
    "    # Load audio file\n",
    "    audio, sample_rate = librosa.load(file_path, sr=sample_rate)\n",
    "\n",
    "    # Compute Mel spectrogram\n",
    "    mel = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_fft=n_fft, hop_length=hop_length, n_mels=128)\n",
    "    # Compute MFCC from the Mel spectrogram\n",
    "    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=n_mfcc)\n",
    "\n",
    "    # Resize spectrograms\n",
    "    mfcc_resized = resize(mfcc, (224, 224, 3), mode='reflect', anti_aliasing=True)\n",
    "    mel_resized = resize(mel, (224, 224, 3), mode='reflect', anti_aliasing=True)\n",
    "\n",
    "    # Clear memory\n",
    "    del audio\n",
    "\n",
    "    return mfcc_resized, mel_resized\n",
    "def process_audio_files(audio_files, audio_folder):\n",
    "    mfcc_train = []\n",
    "    mel_train = []\n",
    "    y_train = []\n",
    "\n",
    "    total_files = len(audio_files)\n",
    "\n",
    "    with tqdm(total=total_files, ncols=80) as pbar:\n",
    "        for file_path in audio_files:\n",
    "            if file_path.endswith(\".wav\"):\n",
    "                # Process audio and extract spectrograms\n",
    "                mfcc, mel = process_audio(file_path)\n",
    "                # Append spectrograms and label to the train arrays\n",
    "                mfcc_train.append(mfcc)\n",
    "                mel_train.append(mel)\n",
    "                # Extract label from subfolder name\n",
    "                label = os.path.basename(os.path.dirname(file_path))\n",
    "                y_train.append(label)\n",
    "                pbar.set_postfix({'file': file_path})\n",
    "                pbar.update()\n",
    "\n",
    "    # Convert train arrays to NumPy arrays\n",
    "    mfcc_train = np.array(mfcc_train)\n",
    "    mel_train = np.array(mel_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    return mfcc_train, mel_train, y_train\n",
    "def main(audio_folder):\n",
    "    audio_files, labels = load_audio_files(audio_folder)\n",
    "    X_mfcc, X_mel, y = process_audio_files(audio_files, audio_folder)\n",
    "    return X_mfcc, X_mel, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 152/152 [00:09<00:00, 15.64it/s, file=/Users/sammerking/Desktop/Datasets\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "audio_folder = ''                        \n",
    "mfcc_test, mel_test, label_test = main(audio_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 835/835 [00:56<00:00, 14.84it/s, file=/Users/sammerking/Desktop/Datasets\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "audio_folder = ''                        \n",
    "mfcc_train, mel_train, label_train = main(audio_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on your label data\n",
    "label_encoder.fit(label_train)\n",
    "\n",
    "# Transform the labels to numerical values\n",
    "y_train_encoded = label_encoder.transform(label_train)\n",
    "y_test_encoded = label_encoder.transform(label_test)\n",
    "\n",
    "# Get the unique class names\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# Create a dictionary to map numerical labels to class names\n",
    "label_to_class = {i: class_name for i, class_name in enumerate(class_names)}\n",
    "\n",
    "# Convert the encoded labels to one-hot encoded vectors\n",
    "label_train_encoded = to_categorical(y_train_encoded)\n",
    "label_test_encoded = to_categorical(y_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "mel_train_norm = np.array(mel_train) / 255  \n",
    "mel_test_norm = np.array(mel_test) / 255      \n",
    "mfcc_train_norm = np.array(mfcc_train) / 255    \n",
    "mfcc_test_norm = np.array(mfcc_test) / 255    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input layers\n",
    "mel_input = Input(shape=(224, 224, 3))  # Modify the shape according to your mel spectrogram dimensions\n",
    "cqt_input = Input(shape=(224, 224, 3))\n",
    "\n",
    "# Convolutional layers for Mel spectrograms\n",
    "mel_conv = Conv2D(32, kernel_size=(3, 3), activation='relu')(mel_input)\n",
    "mel_conv = MaxPooling2D(pool_size=(2, 2))(mel_conv)\n",
    "mel_conv = Conv2D(64, kernel_size=(3, 3), activation='relu')(mel_conv)\n",
    "mel_conv = MaxPooling2D(pool_size=(2, 2))(mel_conv)\n",
    "mel_conv = Conv2D(128, kernel_size=(3, 3), activation='relu')(mel_conv)\n",
    "mel_conv = MaxPooling2D(pool_size=(2, 2))(mel_conv)\n",
    "mel_conv = Flatten()(mel_conv)\n",
    "\n",
    "# Convolutional layers for CQT spectrograms\n",
    "cqt_conv = Conv2D(32, kernel_size=(3, 3), activation='relu')(cqt_input)\n",
    "cqt_conv = MaxPooling2D(pool_size=(2, 2))(cqt_conv)\n",
    "cqt_conv = Conv2D(64, kernel_size=(3, 3), activation='relu')(cqt_conv)\n",
    "cqt_conv = MaxPooling2D(pool_size=(2, 2))(cqt_conv)\n",
    "cqt_conv = Conv2D(128, kernel_size=(3, 3), activation='relu')(cqt_conv)\n",
    "cqt_conv = MaxPooling2D(pool_size=(2, 2))(cqt_conv)\n",
    "cqt_conv = Flatten()(cqt_conv)\n",
    "\n",
    "# Merge the branches\n",
    "merged = concatenate([mel_conv, cqt_conv])\n",
    "\n",
    "# Dense layers for classification\n",
    "dense = Dense(256, activation='relu')(merged)\n",
    "dense = Dropout(0.5)(dense)  # Add dropout with a rate of 0.5\n",
    "dense = Dense(128, activation='relu')(dense)\n",
    "dense = Dropout(0.5)(dense)  # Add dropout with a rate of 0.5\n",
    "output = Dense(5, activation='softmax')(dense)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[mel_input, cqt_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping callback\n",
    "earlystop_callback = EarlyStopping(\n",
    "    monitor='val_accuracy', patience=5, mode='max', verbose=1, restore_best_weights=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 58s 2s/step - loss: 1.6010 - accuracy: 0.3760 - val_loss: 1.0849 - val_accuracy: 0.6776\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 49s 2s/step - loss: 1.3297 - accuracy: 0.4659 - val_loss: 0.8444 - val_accuracy: 0.7697\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 50s 2s/step - loss: 1.1795 - accuracy: 0.5449 - val_loss: 0.8194 - val_accuracy: 0.7829\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 51s 2s/step - loss: 1.0712 - accuracy: 0.5749 - val_loss: 0.7393 - val_accuracy: 0.7763\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 48s 2s/step - loss: 0.8542 - accuracy: 0.6635 - val_loss: 0.8638 - val_accuracy: 0.8158\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 48s 2s/step - loss: 0.7934 - accuracy: 0.6922 - val_loss: 0.7378 - val_accuracy: 0.7895\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 48s 2s/step - loss: 0.6536 - accuracy: 0.7461 - val_loss: 0.7191 - val_accuracy: 0.8289\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 47s 2s/step - loss: 0.5222 - accuracy: 0.8096 - val_loss: 0.9064 - val_accuracy: 0.7961\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 48s 2s/step - loss: 0.4224 - accuracy: 0.8754 - val_loss: 0.7783 - val_accuracy: 0.8684\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 47s 2s/step - loss: 0.3157 - accuracy: 0.9138 - val_loss: 0.7656 - val_accuracy: 0.8026\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 54s 2s/step - loss: 0.2098 - accuracy: 0.9293 - val_loss: 1.3831 - val_accuracy: 0.8487\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 50s 2s/step - loss: 0.3406 - accuracy: 0.9281 - val_loss: 0.7047 - val_accuracy: 0.8882\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 50s 2s/step - loss: 0.1208 - accuracy: 0.9605 - val_loss: 1.5561 - val_accuracy: 0.8224\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 49s 2s/step - loss: 0.1097 - accuracy: 0.9701 - val_loss: 1.5714 - val_accuracy: 0.8224\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 50s 2s/step - loss: 0.0547 - accuracy: 0.9844 - val_loss: 1.2426 - val_accuracy: 0.8553\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 49s 2s/step - loss: 0.1011 - accuracy: 0.9796 - val_loss: 1.5836 - val_accuracy: 0.8289\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9820Restoring model weights from the end of the best epoch: 12.\n",
      "27/27 [==============================] - 50s 2s/step - loss: 0.0515 - accuracy: 0.9820 - val_loss: 1.8707 - val_accuracy: 0.8224\n",
      "Epoch 17: early stopping\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit([mel_train_norm, mfcc_train_norm], label_train_encoded,\n",
    "           batch_size=32, epochs=100, \n",
    "          validation_data=([mel_test_norm, mfcc_test_norm], label_test_encoded),\n",
    "          callbacks=[earlystop_callback]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 447ms/step\n",
      "Accuracy: 0.8881578947368421\n",
      "Precision: 0.8752732121000174\n",
      "Recall: 0.8881578947368421\n",
      "F1 Score: 0.8756137314795778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict([mel_test_norm, mfcc_test_norm])\n",
    "\n",
    "# Convert the predictions from one-hot encoded format to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_true_labels = np.argmax(label_test_encoded, axis=1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
    "precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "recall = recall_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
    "\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
