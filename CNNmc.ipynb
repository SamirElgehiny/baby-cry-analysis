{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAb77yZ9fzMG",
        "outputId": "82e720be-4598-4a45-db9d-54ed63ab7c65"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa.display, os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import librosa.display, os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt \n",
        "from keras.preprocessing import image\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, concatenate, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import librosa\n",
        "from skimage.transform import resize\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "mel_train = []\n",
        "cqt_train = []\n",
        "mel_test = []\n",
        "cqt_test = []\n",
        "label_train = []\n",
        "label_test = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWFb_ALytSi6"
      },
      "outputs": [],
      "source": [
        "def load_images_from_path(path, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for file in os.listdir(path):\n",
        "        images.append(tf.keras.preprocessing.image.img_to_array(tf.keras.preprocessing.image.load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n",
        "        labels.append((label))\n",
        "        \n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBg747MktT4i"
      },
      "outputs": [],
      "source": [
        "images, labels = load_images_from_path('/content/drive/MyDrive/spectro_aug_tt/train/pain', 0)\n",
        "    \n",
        "mel_train += images\n",
        "label_train += labels\n",
        "\n",
        "images, labels = load_images_from_path('/content/drive/MyDrive/spectro_aug_tt/train/burping', 1)\n",
        "    \n",
        "mel_train += images\n",
        "label_train += labels\n",
        "\n",
        "images, labels = load_images_from_path('/content/drive/MyDrive/spectro_aug_tt/train/discomfort', 2)\n",
        "    \n",
        "mel_train += images\n",
        "label_train += labels\n",
        "\n",
        "images, labels = load_images_from_path('/content/drive/MyDrive/spectro_aug_tt/train/hungry', 3)\n",
        "    \n",
        "mel_train += images\n",
        "label_train += labels\n",
        "\n",
        "images, labels = load_images_from_path('/content/drive/MyDrive/spectro_aug_tt/train/tired', 4)\n",
        "    \n",
        "mel_train += images\n",
        "label_train += labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvDnYVEftVQf"
      },
      "outputs": [],
      "source": [
        "images, labels = load_images_from_path('/content/drive/MyDrive/spectro_aug_tt/test/pain', 0)\n",
        "    \n",
        "mel_test += images\n",
        "label_test += labels\n",
        "\n",
        "images, labels = load_images_from_path('/content/drive/MyDrive/spectro_aug_tt/test/burping', 1)\n",
        "    \n",
        "mel_test += images\n",
        "label_test += labels\n",
        "\n",
        "images, labels = load_images_from_path('/content/drive/MyDrive/spectro_aug_tt/test/discomfort', 2)\n",
        "    \n",
        "mel_test += images\n",
        "label_test += labels\n",
        "\n",
        "images, labels = load_images_from_path('/content/drive/MyDrive/spectro_aug_tt/test/hungry', 3)\n",
        "    \n",
        "mel_test += images\n",
        "label_test += labels\n",
        "\n",
        "images, labels = load_images_from_path('/content/drive/MyDrive/spectro_aug_tt/test/tired', 4)\n",
        "    \n",
        "mel_test += images\n",
        "label_test += labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zznIRt0ztXBd"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_images_from_path_1(path):\n",
        "    images = []\n",
        "    \n",
        "    for root, _, files in os.walk(path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            images.append(tf.keras.preprocessing.image.img_to_array(tf.keras.preprocessing.image.load_img(file_path, target_size=(224, 224, 3))))\n",
        "    \n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJ-4SNIMtYSp"
      },
      "outputs": [],
      "source": [
        "images  = load_images_from_path_1('/content/drive/MyDrive/spectro_aug_cqt_tt/train')\n",
        "    \n",
        "cqt_train += images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S5fVQpZtZse"
      },
      "outputs": [],
      "source": [
        "images  = load_images_from_path_1('/content/drive/MyDrive/spectro_aug_cqt_tt/test')\n",
        "\n",
        "cqt_test += images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AghAeD92ta9z"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "mel_train_norm = np.array(mel_train) / 255\n",
        "mel_test_norm = np.array(mel_test) / 255\n",
        "cqt_train_norm = np.array(cqt_train) / 255\n",
        "cqt_test_norm = np.array(cqt_test) / 255\n",
        "\n",
        "label_train_encoded = to_categorical(label_train)\n",
        "label_test_encoded = to_categorical(label_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FwpH1FltetR",
        "outputId": "3e23290c-18c8-4bb7-bd02-eb4949ecb6a5"
      },
      "outputs": [],
      "source": [
        "mel_test_norm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZuJB0EkthTX",
        "outputId": "7184319a-ad4a-4360-e613-0e44f90fc90c"
      },
      "outputs": [],
      "source": [
        "cqt_test_norm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfyF9M2xthfC",
        "outputId": "4dd9e8c2-2d77-4fdb-db58-9dd5947bc86f"
      },
      "outputs": [],
      "source": [
        "mel_train_norm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv_lDwnuthiw",
        "outputId": "2fa0f8d9-1c8b-4e5f-b72c-8060e35b5425"
      },
      "outputs": [],
      "source": [
        "cqt_train_norm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUwDjA1nthqt",
        "outputId": "9b8a4066-c08a-436b-941d-3e79aaf17dab"
      },
      "outputs": [],
      "source": [
        "label_train_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAFJPmlOthzM",
        "outputId": "5fade84d-9275-4081-dfa0-40f9daf803df"
      },
      "outputs": [],
      "source": [
        "label_test_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgbCXGUatcYx"
      },
      "outputs": [],
      "source": [
        "# Define input layers\n",
        "mel_input = Input(shape=(224, 224, 3))  # Modify the shape according to your mel spectrogram dimensions\n",
        "cqt_input = Input(shape=(224, 224, 3))\n",
        "\n",
        "# Convolutional layers for Mel spectrograms\n",
        "mel_conv = Conv2D(32, kernel_size=(3, 3), activation='relu')(mel_input)\n",
        "mel_conv = MaxPooling2D(pool_size=(2, 2))(mel_conv)\n",
        "mel_conv = Conv2D(64, kernel_size=(3, 3), activation='relu')(mel_conv)\n",
        "mel_conv = MaxPooling2D(pool_size=(2, 2))(mel_conv)\n",
        "mel_conv = Conv2D(128, kernel_size=(3, 3), activation='relu')(mel_conv)\n",
        "mel_conv = MaxPooling2D(pool_size=(2, 2))(mel_conv)\n",
        "mel_conv = Flatten()(mel_conv)\n",
        "\n",
        "# Convolutional layers for CQT spectrograms\n",
        "cqt_conv = Conv2D(32, kernel_size=(3, 3), activation='relu')(cqt_input)\n",
        "cqt_conv = MaxPooling2D(pool_size=(2, 2))(cqt_conv)\n",
        "cqt_conv = Conv2D(64, kernel_size=(3, 3), activation='relu')(cqt_conv)\n",
        "cqt_conv = MaxPooling2D(pool_size=(2, 2))(cqt_conv)\n",
        "cqt_conv = Conv2D(128, kernel_size=(3, 3), activation='relu')(cqt_conv)\n",
        "cqt_conv = MaxPooling2D(pool_size=(2, 2))(cqt_conv)\n",
        "cqt_conv = Flatten()(cqt_conv)\n",
        "\n",
        "# Merge the branches\n",
        "merged = concatenate([mel_conv, cqt_conv])\n",
        "\n",
        "# Dense layers for classification\n",
        "dense = Dense(256, activation='relu')(merged)\n",
        "dense = Dropout(0.5)(dense)  # Add dropout with a rate of 0.5\n",
        "dense = Dense(128, activation='relu')(dense)\n",
        "dense = Dropout(0.5)(dense)  # Add dropout with a rate of 0.5\n",
        "output = Dense(5, activation='softmax')(dense)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=[mel_input, cqt_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upEPOy7Qto8J"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define early stopping callback\n",
        "earlystop_callback = EarlyStopping(\n",
        "    monitor='val_accuracy', patience=5, mode='max', verbose=1, restore_best_weights=True\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0nVZIHqtqUw"
      },
      "outputs": [],
      "source": [
        "from skimage.transform import resize\n",
        "\n",
        "def spec_augment(spec, num_time_drop=2, num_freq_drop=2, max_time_stripes=2, max_freq_stripes=2):\n",
        "    augmented_spec = spec.copy()\n",
        "\n",
        "    # Apply time dropping\n",
        "    for _ in range(num_time_drop):\n",
        "        time_start = np.random.randint(0, spec.shape[0] - 1)\n",
        "        time_end = np.random.randint(time_start + 1, spec.shape[0])\n",
        "        augmented_spec[time_start:time_end, :] = 0\n",
        "\n",
        "    # Apply frequency dropping\n",
        "    for _ in range(num_freq_drop):\n",
        "        freq_start = np.random.randint(0, spec.shape[1] - 1)\n",
        "        freq_end = np.random.randint(freq_start + 1, spec.shape[1])\n",
        "        augmented_spec[:, freq_start:freq_end] = 0\n",
        "\n",
        "    # Apply time warping\n",
        "    for _ in range(max_time_stripes):\n",
        "        time_start = np.random.randint(0, spec.shape[0] - 1)\n",
        "        time_end = np.random.randint(time_start + 1, spec.shape[0])\n",
        "        time_mid = np.random.randint(time_start, time_end)\n",
        "        time_mid_val = spec[time_mid, :]\n",
        "        augmented_spec[time_start:time_mid, :] = augmented_spec[time_start:time_mid, :][::-1]\n",
        "        augmented_spec[time_mid:time_end, :] = augmented_spec[time_mid:time_end, :][::-1]\n",
        "        augmented_spec[time_start:time_end, :] = time_mid_val\n",
        "\n",
        "    # Apply frequency warping\n",
        "    for _ in range(max_freq_stripes):\n",
        "        freq_start = np.random.randint(0, spec.shape[1] - 1)\n",
        "        freq_end = np.random.randint(freq_start + 1, spec.shape[1])\n",
        "        freq_mid = np.random.randint(freq_start, freq_end)\n",
        "        freq_mid_val = spec[:, freq_mid]\n",
        "        freq_mid_val = np.expand_dims(freq_mid_val, axis=1)\n",
        "        freq_mid_val = np.repeat(freq_mid_val, freq_end - freq_start, axis=1)\n",
        "        augmented_spec[:, freq_start:freq_end] = freq_mid_val\n",
        "\n",
        "    augmented_spec = resize(augmented_spec, (224, 224, 3), preserve_range=True)\n",
        "\n",
        "    return augmented_spec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uizZqRKYtrq4",
        "outputId": "d0290d72-046b-4087-fe9e-d67c968f1af4"
      },
      "outputs": [],
      "source": [
        "# Define the number of folds\n",
        "n_folds = 5\n",
        "\n",
        "# Create an instance of KFold\n",
        "kf = KFold(n_splits=n_folds, shuffle=True)\n",
        "\n",
        "fold = 1\n",
        "for train_index, val_index in kf.split(mel_train_norm):\n",
        "    print(f'Fold: {fold}')\n",
        "\n",
        "    # Get the training and validation data for the current fold\n",
        "    mel_train_fold = mel_train_norm[train_index]\n",
        "    mel_val_fold = mel_train_norm[val_index]\n",
        "    cqt_train_fold = cqt_train_norm[train_index]\n",
        "    cqt_val_fold = cqt_train_norm[val_index]\n",
        "    label_train_fold = label_train_encoded[train_index]\n",
        "    label_val_fold = label_train_encoded[val_index]\n",
        "\n",
        "    # Calculate the count of each class in the training set\n",
        "    class_counts = np.sum(label_train_fold, axis=0)\n",
        "\n",
        "    # Find the majority class count\n",
        "    majority_class_count = np.max(class_counts)\n",
        "\n",
        "    # Augment the minority classes to match the majority class count using SpecAugment\n",
        "    for i, count in enumerate(class_counts):\n",
        "        if count < majority_class_count:\n",
        "            # Determine the number of SpecAugment augmentations required for the current class\n",
        "            num_augmentations = int(majority_class_count - count)\n",
        "\n",
        "            # Get the indices of the samples belonging to the current class\n",
        "            class_indices = np.where(label_train_fold[:, i] == 1)[0]\n",
        "\n",
        "            # Randomly select samples from the current class for SpecAugment augmentation\n",
        "            selected_indices = np.random.choice(class_indices, size=num_augmentations, replace=True)\n",
        "\n",
        "            # Apply SpecAugment augmentation to the selected samples for both Mel and CQT spectrograms\n",
        "            augmented_mel_train = []\n",
        "            augmented_cqt_train = []\n",
        "            augmented_labels = []\n",
        "            for idx in selected_indices:\n",
        "                augmented_mel_spec = spec_augment(mel_train_fold[idx])\n",
        "                augmented_cqt_spec = spec_augment(cqt_train_fold[idx])\n",
        "                augmented_label = label_train_fold[idx]\n",
        "                augmented_mel_train.append(augmented_mel_spec)\n",
        "                augmented_cqt_train.append(augmented_cqt_spec)\n",
        "                augmented_labels.append(augmented_label)\n",
        "            augmented_mel_train = np.array(augmented_mel_train)\n",
        "            augmented_cqt_train = np.array(augmented_cqt_train)\n",
        "            augmented_labels = np.array(augmented_labels)\n",
        "\n",
        "            # Concatenate the augmented samples with the original training data and labels\n",
        "            mel_train_fold = np.concatenate((mel_train_fold, augmented_mel_train))\n",
        "            cqt_train_fold = np.concatenate((cqt_train_fold, augmented_cqt_train))\n",
        "            label_train_fold = np.concatenate((label_train_fold, augmented_labels))\n",
        "\n",
        "    # Fit the model using the augmented data\n",
        "    history = model.fit(\n",
        "        [mel_train_fold, cqt_train_fold],\n",
        "        label_train_fold,\n",
        "        batch_size=32,\n",
        "        epochs=100,\n",
        "        validation_data=([mel_test_norm, cqt_test_norm], label_test_encoded),\n",
        "        callbacks=[earlystop_callback]\n",
        "    )\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    fold += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvUCtaEztuWV",
        "outputId": "aa4b320b-4c9d-46d2-cc6c-f7689c185f20"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict([mel_test_norm, cqt_test_norm])\n",
        "\n",
        "# Convert the predictions from one-hot encoded format to class labels\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "y_true_labels = np.argmax(label_test_encoded, axis=1)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_true_labels, y_pred_labels)\n",
        "precision = precision_score(y_true_labels, y_pred_labels, average='weighted')\n",
        "recall = recall_score(y_true_labels, y_pred_labels, average='weighted')\n",
        "f1 = f1_score(y_true_labels, y_pred_labels, average='weighted')\n",
        "\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyh4qdhFtuZ4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "confusion_mat = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "\n",
        "# Calculate accuracy scores for each class\n",
        "class_accuracy = confusion_mat.diagonal() / confusion_mat.sum(axis=1)\n",
        "\n",
        "# Print the accuracy scores for each class\n",
        "for i, acc in enumerate(class_accuracy):\n",
        "    print(f\"Accuracy for class {i}: {acc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcLln5XGtuke"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the training history\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# Plot the training curve\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot the loss curve\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot the accuracy curve\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_acc, 'b-', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atWw_wQX3O6D"
      },
      "outputs": [],
      "source": [
        "  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
